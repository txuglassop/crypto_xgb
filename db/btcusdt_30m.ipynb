{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "# get from /notebooks/ to /src/\n",
    "src_path = Path(\"..\", \"src\")\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
      "       'base_asset_volume', 'no_trades', 'taker_buy_vol',\n",
      "       'taker_buy_base_asset_vol'],\n",
      "      dtype='object')\n",
      "(89869, 10)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "# the following is specific to a 3 class model. it will be different for 5\n",
    "down_margin = 0.0038\n",
    "up_margin = 0.0065\n",
    "\n",
    "lag_factor = 5\n",
    "test_size = 0.20\n",
    "\n",
    "data = \"BTCUSDT_30m_2020.csv\"\n",
    "\n",
    "from session_info import SessionInfo\n",
    "\n",
    "session = SessionInfo(\n",
    "    data, num_classes, lag_factor, test_size,\n",
    "    up_margin=up_margin, down_margin=down_margin\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"./../input/\" + data)\n",
    "df.drop(df.columns[df.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)\n",
    "\n",
    "# drop rows where volume == 0\n",
    "df = df.loc[df['volume'] != 0]\n",
    "\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_max = 2684.842810127005, s_min = 0.6427807644221296\n",
      "s_max = 3290.051786594691, s_min = 5.284572232869327\n",
      "s_max = 3881.9753149568924, s_min = 14.933965888037248\n",
      "(89743, 196)\n",
      "Jump: down, Count: 7838\n",
      "Jump: neutral, Count: 78619\n",
      "Jump: up, Count: 3286\n"
     ]
    }
   ],
   "source": [
    "import add_features as af\n",
    "import feature_engineering as fe\n",
    "reload(af)\n",
    "reload(fe)\n",
    "\n",
    "df = af.add_features(df, session)\n",
    "\n",
    "#df = df.dropna()\n",
    "# #for lag in range(1, lag_factor+1):\n",
    "#     for col in cols:\n",
    "#         newcol = np.zeros(df.shape[0]) * np.nan\n",
    "#         newcol[lag:] = df[col].values[:-lag]\n",
    "#         df.insert(len(df.columns), \"{0}_{1}\".format(col, lag), newcol)\n",
    "\n",
    "# df = df.dropna()\n",
    "\n",
    "# move the jump and target variable (jump_tmr) to the end\n",
    "df = df[[col for col in df.columns if col not in ['next_jump']] + ['next_jump']]\n",
    "\n",
    "# log what features we are using\n",
    "features = [col for col in df.columns if col not in ['timestamp', 'next_jump']]\n",
    "session.add_features(features)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "unique, counts = np.unique(df['next_jump'], return_counts=True)\n",
    "for u,c in zip(unique, counts):\n",
    "    print(f'Jump: {u}, Count: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility_functions import get_jump_lookup\n",
    "\n",
    "jump_lookup = get_jump_lookup(num_classes=num_classes)\n",
    "\n",
    "\n",
    "X = df.drop(['timestamp', 'next_jump'], axis=1).copy()\n",
    "y = df['next_jump'].copy()\n",
    "y = y.map(jump_lookup)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f446bc11010>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "X_pca = pca.fit(X_scaled)\n",
    "explain_variance = pca.explained_variance_ratio_\n",
    "plt.plot(pca.explained_variance_, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Optimising Group 1 ======\n",
      "STUDY NAME:  xgboost\n",
      "-------------------------------------------------------\n",
      "EVALUATION METRIC:  fbeta_eval\n",
      "-------------------------------------------------------\n",
      "BEST CV SCORE:  0.4625484\n",
      "-------------------------------------------------------\n",
      "OPTIMAL GROUP - 1 PARAMS:  {'max_depth': 14, 'min_child_weight': 7.3924497885029625}\n",
      "-------------------------------------------------------\n",
      "BEST TRIAL FrozenTrial(number=100, state=1, values=[0.4625484], datetime_start=datetime.datetime(2025, 2, 19, 9, 49, 32, 893690), datetime_complete=datetime.datetime(2025, 2, 19, 9, 49, 54, 991987), params={'max_depth': 14, 'min_child_weight': 7.3924497885029625}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.46551219999999993, 1: 0.4658392, 2: 0.46704560000000006, 3: 0.467492, 4: 0.46896460000000006, 5: 0.46806220000000004, 6: 0.4670992, 7: 0.4666530000000001, 8: 0.4666456, 9: 0.4641197999999999, 10: 0.46441299999999996, 11: 0.4625484, 12: 0.46433179999999996, 13: 0.46321080000000003, 14: 0.46361680000000005, 15: 0.46524780000000004, 16: 0.46501960000000003, 17: 0.4656378, 18: 0.4653378, 19: 0.4661318, 20: 0.46543239999999997, 21: 0.46386780000000005}, distributions={'max_depth': IntDistribution(high=30, log=False, low=2, step=1), 'min_child_weight': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None)}, trial_id=101, value=None)\n",
      "-------------------------------------------------------\n",
      "Params after updating group 1:  {'num_boost_round': 200, 'learning_rate': 0.01, 'objective': 'multi:softprob', 'num_class': 3, 'gamma': 0.001, 'max_depth': 14, 'min_child_weight': 7.3924497885029625}\n",
      "\n",
      "\n",
      "\n",
      "====== Optimising Group 2 ======\n",
      "STUDY NAME:  xgboost\n",
      "-------------------------------------------------------\n",
      "EVALUATION METRIC:  fbeta_eval\n",
      "-------------------------------------------------------\n",
      "BEST CV SCORE:  0.4625484\n",
      "-------------------------------------------------------\n",
      "OPTIMAL GROUP - 2 PARAMS:  {'max_depth': 14, 'min_child_weight': 7.3924497885029625}\n",
      "-------------------------------------------------------\n",
      "BEST TRIAL FrozenTrial(number=100, state=1, values=[0.4625484], datetime_start=datetime.datetime(2025, 2, 19, 9, 49, 32, 893690), datetime_complete=datetime.datetime(2025, 2, 19, 9, 49, 54, 991987), params={'max_depth': 14, 'min_child_weight': 7.3924497885029625}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.46551219999999993, 1: 0.4658392, 2: 0.46704560000000006, 3: 0.467492, 4: 0.46896460000000006, 5: 0.46806220000000004, 6: 0.4670992, 7: 0.4666530000000001, 8: 0.4666456, 9: 0.4641197999999999, 10: 0.46441299999999996, 11: 0.4625484, 12: 0.46433179999999996, 13: 0.46321080000000003, 14: 0.46361680000000005, 15: 0.46524780000000004, 16: 0.46501960000000003, 17: 0.4656378, 18: 0.4653378, 19: 0.4661318, 20: 0.46543239999999997, 21: 0.46386780000000005}, distributions={'max_depth': IntDistribution(high=30, log=False, low=2, step=1), 'min_child_weight': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None)}, trial_id=101, value=None)\n",
      "-------------------------------------------------------\n",
      "Params after updating group 2:  {'num_boost_round': 200, 'learning_rate': 0.01, 'objective': 'multi:softprob', 'num_class': 3, 'gamma': 0.001, 'max_depth': 14, 'min_child_weight': 7.3924497885029625, 'subsample': 0.8064274390960682, 'colsample_bytree': 0.6638783978185165}\n",
      "\n",
      "\n",
      "\n",
      "====== Optimising Group 3 ======\n",
      "STUDY NAME:  xgboost\n",
      "-------------------------------------------------------\n",
      "EVALUATION METRIC:  fbeta_eval\n",
      "-------------------------------------------------------\n",
      "BEST CV SCORE:  0.4625484\n",
      "-------------------------------------------------------\n",
      "OPTIMAL GROUP - 3 PARAMS:  {'max_depth': 14, 'min_child_weight': 7.3924497885029625}\n",
      "-------------------------------------------------------\n",
      "BEST TRIAL FrozenTrial(number=100, state=1, values=[0.4625484], datetime_start=datetime.datetime(2025, 2, 19, 9, 49, 32, 893690), datetime_complete=datetime.datetime(2025, 2, 19, 9, 49, 54, 991987), params={'max_depth': 14, 'min_child_weight': 7.3924497885029625}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.46551219999999993, 1: 0.4658392, 2: 0.46704560000000006, 3: 0.467492, 4: 0.46896460000000006, 5: 0.46806220000000004, 6: 0.4670992, 7: 0.4666530000000001, 8: 0.4666456, 9: 0.4641197999999999, 10: 0.46441299999999996, 11: 0.4625484, 12: 0.46433179999999996, 13: 0.46321080000000003, 14: 0.46361680000000005, 15: 0.46524780000000004, 16: 0.46501960000000003, 17: 0.4656378, 18: 0.4653378, 19: 0.4661318, 20: 0.46543239999999997, 21: 0.46386780000000005}, distributions={'max_depth': IntDistribution(high=30, log=False, low=2, step=1), 'min_child_weight': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None)}, trial_id=101, value=None)\n",
      "-------------------------------------------------------\n",
      "Params after updating group 3:  {'num_boost_round': 300, 'learning_rate': 0.024548916918104596, 'objective': 'multi:softprob', 'num_class': 3, 'gamma': 0.001, 'max_depth': 14, 'min_child_weight': 7.3924497885029625, 'subsample': 0.8064274390960682, 'colsample_bytree': 0.6638783978185165}\n",
      "\n",
      "\n",
      "\n",
      "====== Optimising Group 4 ======\n",
      "STUDY NAME:  xgboost\n",
      "-------------------------------------------------------\n",
      "EVALUATION METRIC:  fbeta_eval\n",
      "-------------------------------------------------------\n",
      "BEST CV SCORE:  0.4625484\n",
      "-------------------------------------------------------\n",
      "OPTIMAL GROUP - 4 PARAMS:  {'max_depth': 14, 'min_child_weight': 7.3924497885029625}\n",
      "-------------------------------------------------------\n",
      "BEST TRIAL FrozenTrial(number=100, state=1, values=[0.4625484], datetime_start=datetime.datetime(2025, 2, 19, 9, 49, 32, 893690), datetime_complete=datetime.datetime(2025, 2, 19, 9, 49, 54, 991987), params={'max_depth': 14, 'min_child_weight': 7.3924497885029625}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.46551219999999993, 1: 0.4658392, 2: 0.46704560000000006, 3: 0.467492, 4: 0.46896460000000006, 5: 0.46806220000000004, 6: 0.4670992, 7: 0.4666530000000001, 8: 0.4666456, 9: 0.4641197999999999, 10: 0.46441299999999996, 11: 0.4625484, 12: 0.46433179999999996, 13: 0.46321080000000003, 14: 0.46361680000000005, 15: 0.46524780000000004, 16: 0.46501960000000003, 17: 0.4656378, 18: 0.4653378, 19: 0.4661318, 20: 0.46543239999999997, 21: 0.46386780000000005}, distributions={'max_depth': IntDistribution(high=30, log=False, low=2, step=1), 'min_child_weight': FloatDistribution(high=10000000000.0, log=True, low=1e-10, step=None)}, trial_id=101, value=None)\n",
      "-------------------------------------------------------\n",
      "Params after updating group 4:  {'num_boost_round': 200, 'learning_rate': 0.01, 'objective': 'multi:softprob', 'num_class': 3, 'gamma': 0.007077546980661846, 'max_depth': 14, 'min_child_weight': 7.3924497885029625, 'subsample': 0.8064274390960682, 'colsample_bytree': 0.6638783978185165}\n",
      "\n",
      "\n",
      "\n",
      "====== Final Optimal Parameters ======\n",
      "{'num_boost_round': 200, 'learning_rate': 0.01, 'objective': 'multi:softprob', 'num_class': 3, 'gamma': 0.007077546980661846, 'max_depth': 14, 'min_child_weight': 7.3924497885029625, 'subsample': 0.8064274390960682, 'colsample_bytree': 0.6638783978185165}\n"
     ]
    }
   ],
   "source": [
    "import optimise_xgb as oxgb\n",
    "reload(oxgb)\n",
    "import eval_metrics\n",
    "\n",
    "eval_metric = eval_metrics.fbeta_eval\n",
    "\n",
    "sys.stderr = open('optuna_errors.log', 'w')\n",
    "\n",
    "params = oxgb.stepwise_optimisation(X, y, 3, eval_metric, data=os.path.splitext(data)[0], trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_boost_round': 200, 'learning_rate': 0.01, 'objective': 'multi:softprob', 'num_class': 3, 'gamma': 0.5682605273867319, 'max_depth': 18, 'min_child_weight': 5.7389146607612446e-08, 'subsample': 0.6210278383874708, 'colsample_bytree': 0.7689341785103883}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Optimising Group 1 ======\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mstepwise_optimisation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m stepwise_optimisation(X, y, \u001b[38;5;241m3\u001b[39m, eval_metric, data\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(data)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m params \u001b[38;5;241m=\u001b[39m stepwise_optimisation(X, y, \u001b[38;5;241m3\u001b[39m, eval_metric, data\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(data)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/trading/crypto_xgb/notebooks/../src/optimise_xgb.py:105\u001b[0m, in \u001b[0;36mstepwise_optimisation\u001b[0;34m(X_train, y_train, num_classes, eval_metric, data, trials)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m====== Optimising Group \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m     update_params \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_optimisation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgboost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     final_params\u001b[38;5;241m.\u001b[39mupdate(update_params)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParams after updating group \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m, final_params)\n",
      "File \u001b[0;32m~/trading/crypto_xgb/notebooks/../src/optimise_xgb.py:65\u001b[0m, in \u001b[0;36m_execute_optimisation\u001b[0;34m(X_train, y_train, num_classes, study_name, group, score, trials, data, params, direction)\u001b[0m\n\u001b[1;32m     55\u001b[0m pruner \u001b[38;5;241m=\u001b[39m MedianPruner(n_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     57\u001b[0m study \u001b[38;5;241m=\u001b[39m create_study(\n\u001b[1;32m     58\u001b[0m     direction\u001b[38;5;241m=\u001b[39mdirection,\n\u001b[1;32m     59\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     pruner\u001b[38;5;241m=\u001b[39mpruner\n\u001b[1;32m     63\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTUDY NAME: \u001b[39m\u001b[38;5;124m'\u001b[39m, study_name)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/trading/crypto_live/env/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/trading/crypto_live/env/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/trading/crypto_live/env/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/trading/crypto_live/env/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/trading/crypto_live/env/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/trading/crypto_xgb/notebooks/../src/optimise_xgb.py:66\u001b[0m, in \u001b[0;36m_execute_optimisation.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     55\u001b[0m pruner \u001b[38;5;241m=\u001b[39m MedianPruner(n_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     57\u001b[0m study \u001b[38;5;241m=\u001b[39m create_study(\n\u001b[1;32m     58\u001b[0m     direction\u001b[38;5;241m=\u001b[39mdirection,\n\u001b[1;32m     59\u001b[0m     study_name\u001b[38;5;241m=\u001b[39mstudy_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     pruner\u001b[38;5;241m=\u001b[39mpruner\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     65\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43m_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     67\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mtrials,\n\u001b[1;32m     68\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTUDY NAME: \u001b[39m\u001b[38;5;124m'\u001b[39m, study_name)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/trading/crypto_xgb/notebooks/../src/optimise_xgb.py:42\u001b[0m, in \u001b[0;36m_objective\u001b[0;34m(trial, X, y, num_classes, group, score, params)\u001b[0m\n\u001b[1;32m     38\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m learning_rate\n\u001b[1;32m     40\u001b[0m pruning_callback \u001b[38;5;241m=\u001b[39m XGBoostPruningCallback(trial, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m score\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mstratified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_boost_round\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpruning_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m score\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/trading/crypto_live/env/lib/python3.12/site-packages/xgboost/training.py:570\u001b[0m, in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle, custom_metric)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks_container\u001b[38;5;241m.\u001b[39mbefore_iteration(booster, i, dtrain, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m should_break \u001b[38;5;241m=\u001b[39m callbacks_container\u001b[38;5;241m.\u001b[39mafter_iteration(booster, i, dtrain, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    573\u001b[0m res \u001b[38;5;241m=\u001b[39m callbacks_container\u001b[38;5;241m.\u001b[39maggregated_cv\n",
      "File \u001b[0;32m~/trading/crypto_live/env/lib/python3.12/site-packages/xgboost/training.py:229\u001b[0m, in \u001b[0;36m_PackedBooster.update\u001b[0;34m(self, iteration, obj)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterate through folds for update\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcvfolds:\n\u001b[0;32m--> 229\u001b[0m     \u001b[43mfold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/trading/crypto_live/env/lib/python3.12/site-packages/xgboost/training.py:215\u001b[0m, in \u001b[0;36mCVPack.update\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, iteration: \u001b[38;5;28mint\u001b[39m, fobj: Optional[Objective]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \"Update the boosters for one iteration\"\"\"\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/trading/crypto_live/env/lib/python3.12/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = stepwise_optimisation(X, y, 3, eval_metric, data=os.path.splitext(data)[0], trials=50)\n",
    "params = stepwise_optimisation(X, y, 3, eval_metric, data=os.path.splitext(data)[0], trials=50)\n",
    "params = stepwise_optimisation(X, y, 3, eval_metric, data=os.path.splitext(data)[0], trials=50)\n",
    "params = stepwise_optimisation(X, y, 3, eval_metric, data=os.path.splitext(data)[0], trials=50)\n",
    "params = stepwise_optimisation(X, y, 3, eval_metric, data=os.path.splitext(data)[0], trials=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
